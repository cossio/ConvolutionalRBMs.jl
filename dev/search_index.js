var documenterSearchIndex = {"docs":
[{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"EditURL = \"https://github.com/cossio/ConvolutionalRBMs.jl/blob/master/docs/src/literate/MNIST_conv.jl\"","category":"page"},{"location":"literate/MNIST_conv/#MNIST","page":"MNIST conv","title":"MNIST","text":"","category":"section"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"We begin by importing the required packages. We load MNIST via the MLDatasets.jl package.","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"import Makie\nimport CairoMakie\nimport MLDatasets\nimport Flux\nimport RestrictedBoltzmannMachines as RBMs\nimport ConvolutionalRBMs as ConvRBMs\nusing Statistics: mean, var, std\nusing ValueHistories: MVHistory\nusing Random: bitrand\nusing RestrictedBoltzmannMachines: visible, hidden, weights, log_pseudolikelihood, transfer_sample\nnothing #hide","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"Useful function to plot MNIST digits.","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"\"\"\"\n    imggrid(A)\n\nGiven a four dimensional tensor `A` of size `(width, height, ncols, nrows)`\ncontaining `width x height` images in a grid of `nrows x ncols`, this returns\na matrix of size `(width * ncols, height * nrows)`, that can be plotted in a heatmap\nto display all images.\n\"\"\"\nfunction imggrid(A::AbstractArray{<:Any,4})\n    (width, height, ncols, nrows) = size(A)\n    return reshape(permutedims(A, (1,3,2,4)), width * ncols, height * nrows)\nend\n\nimggrid_border(A::AbstractArray{<:Any,4}, borderval = 1) = imggrid(bordered(A, borderval))\n\nfunction bordered(A::AbstractArray{<:Any,4}, borderval = 1)\n    return mapslices(A; dims=(1,2)) do img::AbstractMatrix\n        [   fill(borderval, 1, size(img, 2) + 2);\n            fill(borderval, size(img, 1)) img fill(borderval, size(img, 1));\n            fill(borderval, 1, size(img, 2) + 2)\n        ]\n    end\nend","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"Load MNIST dataset.","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"Float = Float32\ntrain_x, train_y = MLDatasets.MNIST.traindata()\ndigit = 2\ntrain_x = Array{Float}(train_x[:, :, train_y .== digit] .≥ 0.5)\ntrain_y = train_y[train_y .== digit]\nprintln(length(train_y), \" training images (for digit = $digit)\")\nnothing #hide","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"Reshape for convolutional input","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"train_x = reshape(train_x, 1, 28, 28, :) # channel dims, input dims, batch dims\nnothing #hide","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"Initialize the convolutional RBM.","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"rbm = ConvRBMs.BinaryConvRBM(Float, 1, 16, (15,15); pad=:same, pool=true)\nRBMs.initialize!(rbm, train_x)\nnothing #hide","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"Pseudolikelihood before training","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"idx = rand(1:size(train_x)[end], 256)\nmean(@time log_pseudolikelihood(rbm, train_x[:,:,:,idx]))","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"Initialize training","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"batchsize = 256\noptim = Flux.ADAM()\nvm = transfer_sample(visible(rbm), falses(1, 28, 28, batchsize)) # fantasy chains\nhistory = MVHistory()\nnothing #hide","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"Train!","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"@time for iter in 1:20\n    ConvRBMs.pcd!(rbm, train_x; vm, history, batchsize, optim, epochs=5)\n    lpl = log_pseudolikelihood(rbm, train_x[:, :, :, rand(1:size(train_x)[end], 1024)])\n    push!(history, :lpl_ave, mean(lpl))\n    push!(history, :lpl_std, std(lpl))\nend\nnothing #hide","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"Plot of log-pseudolikelihood of trian data during learning.","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"fig = Makie.Figure(resolution=(600,300))\nax = Makie.Axis(fig[1,1], xlabel = \"train time\", ylabel=\"pseudolikelihood\")\nMakie.band!(ax, get(history, :lpl_ave)[1],\n    get(history, :lpl_ave)[2] - get(history, :lpl_std)[2]/2,\n    get(history, :lpl_ave)[2] + get(history, :lpl_std)[2]/2,\n    color=:lightblue\n)\nMakie.lines!(ax, get(history, :lpl_ave)..., color=:blue)\nfig","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"Now let's generate some random RBM samples.","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"nrows, ncols = 10, 15\nnsteps = 1000\nfantasy_F = zeros(nrows*ncols, nsteps)\nfantasy_x = bitrand(1,28,28,nrows*ncols)\nfantasy_F[:,1] .= RBMs.free_energy(rbm, fantasy_x)\n@time for t in 2:nsteps\n    fantasy_x .= RBMs.sample_v_from_v(rbm, fantasy_x)\n    fantasy_F[:,t] .= RBMs.free_energy(rbm, fantasy_x)\nend\nnothing #hide","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"Check equilibration of sampling","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"fig = Makie.Figure(resolution=(400,300))\nax = Makie.Axis(fig[1,1], xlabel=\"sampling time\", ylabel=\"free energy\")\nfantasy_F_μ = vec(mean(fantasy_F; dims=1))\nfantasy_F_σ = vec(std(fantasy_F; dims=1))\nMakie.band!(ax, 1:nsteps, fantasy_F_μ - fantasy_F_σ/2, fantasy_F_μ + fantasy_F_σ/2)\nMakie.lines!(ax, 1:nsteps, fantasy_F_μ)\nfig","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"Plot the resulting samples.","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"fig = Makie.Figure(resolution=(40ncols, 40nrows))\nax = Makie.Axis(fig[1,1], yreversed=true)\nMakie.image!(ax, imggrid(reshape(fantasy_x, 28, 28, ncols, nrows)), colorrange=(1,0))\nMakie.hidedecorations!(ax)\nMakie.hidespines!(ax)\nfig","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"Plot the filters learned","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"wncols = 4; wnrows = 4\nfig = Makie.Figure(resolution=(80wncols, 80wnrows))\nax = Makie.Axis(fig[1,1], yreversed=true)\nMakie.image!(ax, imggrid_border(reshape(rbm.w ./ maximum(abs, rbm.w; dims=(2,3)), 15, 15, wncols, wnrows)))\nMakie.hidedecorations!(ax)\nMakie.hidespines!(ax)\nfig","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"","category":"page"},{"location":"literate/MNIST_conv/","page":"MNIST conv","title":"MNIST conv","text":"This page was generated using Literate.jl.","category":"page"},{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [ConvolutionalRBMs]","category":"page"},{"location":"reference/#ConvolutionalRBMs.ConvRBM-Tuple{RestrictedBoltzmannMachines.AbstractLayer, RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"ConvolutionalRBMs.ConvRBM","text":"ConvRBM(visible, hidden, weights; stride = 1, pad = 0, dilation = 1, groups = 1, pool = false)\n\nConvolutional RBM.\n\npad == :same uses samepad(...) to infer a padding that preserves spatial dimensions.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.ConvRBM-Union{Tuple{T}, Tuple{RestrictedBoltzmannMachines.AbstractLayer, RestrictedBoltzmannMachines.AbstractLayer, Tuple{Vararg{Int64, N}} where N}, Tuple{RestrictedBoltzmannMachines.AbstractLayer, RestrictedBoltzmannMachines.AbstractLayer, Tuple{Vararg{Int64, N}} where N, Type{T}}} where T","page":"Reference","title":"ConvolutionalRBMs.ConvRBM","text":"ConvRBM(visible, hidden, kernel_size; kwargs...)\n\nConvolutional RBM with given kernel_size.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.BinaryConvRBM-Tuple{AbstractArray, AbstractArray, AbstractArray}","page":"Reference","title":"ConvolutionalRBMs.BinaryConvRBM","text":"BinaryConvRBM(visible_fields, hidden_fields, w)\n\nConvolutional RBM with binary visible and hidden units, with fields a and b and weights w.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.BinaryConvRBM-Union{Tuple{T}, Tuple{Type{T}, Union{Int64, Tuple{Vararg{Int64, N}} where N}, Union{Int64, Tuple{Vararg{Int64, N}} where N}, Union{Int64, Tuple{Vararg{Int64, N}} where N}}} where T","page":"Reference","title":"ConvolutionalRBMs.BinaryConvRBM","text":"BinaryConvRBM(visible_size, hidden_size, kernel_size)\nBinaryConvRBM(T, visible_size, hidden_size, kernel_size)\n\nConvolutional binary RBM with given dimensions, and parameters initialized to zero of type T (= Float64 by default).\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.cartesian_sample_from_logits-Tuple{AbstractArray}","page":"Reference","title":"ConvolutionalRBMs.cartesian_sample_from_logits","text":"cartesian_sample_from_logits(logits; dims=1)\n\nReturns an array X of indices sampled from CartesianIndices(logits) along dimensions dims, with probabilities P = softmax(logits; dims). In particular, dimensions dims of X are singleton.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.conv_h2v-Union{Tuple{N}, Tuple{AbstractArray{T, N} where T, AbstractArray{T, N} where T}} where N","page":"Reference","title":"ConvolutionalRBMs.conv_h2v","text":"conv_h2v(w, v)\n\nInternal function used to compute inputs from a hidden configurations h to the visible layer, where w are the convolutional RBM weights.\n\nI_i_1dotsi_n^k_1dotsk_nb = sum_cj_1dotsj_n w_cj_1dotsj_nmu v_cj_1+k_1-1dotsj_n+k_n-1b\n\nAssumes that:\n\nw is of size (C,J₁,...,Jₙ,M)\nh is of size (M,K₁,...,Kₙ,B)\n\nHere C is the channel dimension, M is the number of hidden units and B is the batch size. These three dimensions are flat, so that the hidden and batch dimensions must be flattened before calling conv_h2v. In the default case with stride = 1, pad = 0, dilation = 1, ..., the output I is of size (C, K₁ + J₁ - 1, ..., Kₙ + Jₙ - 1, B).\n\nwarning: Warning\nThis is an internal function, not part of the public API. It is subject to change.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.conv_v2h-Union{Tuple{N}, Tuple{AbstractArray{T, N} where T, AbstractArray{T, N} where T}} where N","page":"Reference","title":"ConvolutionalRBMs.conv_v2h","text":"conv_v2h(w, v)\n\nInternal function used to compute inputs from a visible configurations v to the hidden layer, where w are the convolutional RBM weights.\n\nI_mu^k_1dotsk_nb = sum_cj_1dotsj_n w_cj_1dotsj_nmu v_cj_1+k_1-1dotsj_n+k_n-1b\n\nAssumes that:\n\nw is of size (C,J₁,...,Jₙ,M)\nv is of size (C,N₁,...,Nₙ,B)\n\nHere C is the flattened channel dimension, M is the number of hidden units and B is the batch size. Therefore the hidden and batch dimensions must be flattened before calling conv_v2h. In the default case with stride = 1, pad = 0, dilation = 1, ..., the output I is of size (M, N₁ - J₁ + 1, ..., Nₙ - Jₙ + 1, B),\n\nwarning: Warning\nThis is an internal function and is not part of the public API.\n\nwarning: Warning\nOnly works for n = 1, 2, 3 due to a technical limitations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.expand_tuple-Union{Tuple{N}, Tuple{Val{N}, Int64}} where N","page":"Reference","title":"ConvolutionalRBMs.expand_tuple","text":"expand_tuple(Val(N), t)\n\nExpands t into a tuple of length N.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.hankel-Union{Tuple{N}, Tuple{ConvolutionalRBMs.ConvRBM, Tuple{Vararg{Int64, N}}}} where N","page":"Reference","title":"ConvolutionalRBMs.hankel","text":"hankel(convrbm, input_size)\n\nReturns a dense RBM equivalent to convrbm with replicated weights.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.hankel_image-Union{Tuple{N2}, Tuple{N}, Tuple{C}, Tuple{AbstractArray, Tuple{Vararg{Int64, C}}, Tuple{Vararg{Int64, N}}, Tuple{Vararg{Int64, N}}, Tuple{Vararg{Int64, N2}}, Tuple{Vararg{Int64, N}}}} where {C, N, N2}","page":"Reference","title":"ConvolutionalRBMs.hankel_image","text":"hankel_image(v, channel_size, kernel_size)\n\nCreates a Hankel array from v with channel and kernel dimensions channel_size and kernel_size, respectively. The returned array V satisfies:\n\nV_cjkn = V_cj+k-1n\n\nwhere c,j,k,n are multi-indices, with c traversing channels, j traversing the kernel, k the convolution output, and n batches.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.hankel_weight-Union{Tuple{N}, Tuple{C}, Tuple{AbstractArray, Tuple{Vararg{Int64, C}}, Tuple{Vararg{Int64, N}}}} where {C, N}","page":"Reference","title":"ConvolutionalRBMs.hankel_weight","text":"hankel_weight(w, channel_size, input_size)\n\nCreates a Hankel array from v with channel and kernel dimensions channel_size and kernel_size, respectively. The returned array V satisfies:\n\nV_cjkn = V_cj+k-1n\n\nwhere c,j,k,n are multi-indices, with c traversing channels, j traversing the kernel, k the convolution output, and n batches.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.hsizes-Tuple{ConvolutionalRBMs.ConvRBM, AbstractArray}","page":"Reference","title":"ConvolutionalRBMs.hsizes","text":"hsizes(convrbm, h) -> (hidden_size, output_size, batch_size)\n\nReturns a (named) tuple decomposition of the size of h, such that:\n\nsize(h) == (hidden_size..., output_size..., batch_size...)\n\nThrows an error if h is not consistent with this size.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.out2in-Union{Tuple{N}, Tuple{CartesianIndex{N}, CartesianIndex{N}}} where N","page":"Reference","title":"ConvolutionalRBMs.out2in","text":"out2in(j, k; stride = 1, dilation = 1)\n\nGiven kernel index j and output index k, gets the corresponding input index i.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.output_size-Tuple{ConvolutionalRBMs.ConvRBM, AbstractArray}","page":"Reference","title":"ConvolutionalRBMs.output_size","text":"output_size(rbm, v)\n\nOutput size of the convolution.\n\nIf v has batch_size batches, then output_size(rbm, v) returns output_size such that:\n\nsize(h) == (hidden_size..., output_size..., batch_size...)\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.output_size-Union{Tuple{N}, Tuple{Tuple{Vararg{Int64, N}}, Tuple{Vararg{Int64, N}}}} where N","page":"Reference","title":"ConvolutionalRBMs.output_size","text":"output_size(kernel_size, input_size; stride = 1, pad = 0, dilation = 1)\n\nOutput size of the convolution.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.parts-Tuple{ConvolutionalRBMs.DenseConvRBM}","page":"Reference","title":"ConvolutionalRBMs.parts","text":"parts(denseconvrbm)\n\nExtracts the dense and convolutional parts of a DenseConvRBM.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.randgumbel-Union{Tuple{}, Tuple{Type{T}}, Tuple{T}} where T","page":"Reference","title":"ConvolutionalRBMs.randgumbel","text":"randgumbel(T = Float64)\n\nGenerates a random Gumbel variate.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.replicate-Tuple{RestrictedBoltzmannMachines.AbstractLayer, Vararg{Int64}}","page":"Reference","title":"ConvolutionalRBMs.replicate","text":"replicate(layer, n...)\n\nReturns a new layer of size (size(layer)..., n...) by repeating the original layer along the new dimensions.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.reshape_maybe-Tuple{Number, Tuple{}}","page":"Reference","title":"ConvolutionalRBMs.reshape_maybe","text":"reshape_maybe(x, shape)\n\nLike reshape(x, shape), except that zero-dimensional outputs are returned as scalars.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.samepad","page":"Reference","title":"ConvolutionalRBMs.samepad","text":"samepad(kernel_size, dilation = 1)\n\nComputes padding such that the input and output spatial sizes of the convolution are the same.\n\nIf stride > 1, then size(output, d) * stride[d] == size(input, d) for each spatial dimension d.\n\n\n\n\n\n","category":"function"},{"location":"reference/#ConvolutionalRBMs.splitpad-Union{Tuple{Tuple{Vararg{Int64, N}}}, Tuple{N}} where N","page":"Reference","title":"ConvolutionalRBMs.splitpad","text":"splitpad(pad)\n\nGiven pad = (x_lo, x_hi, y_lo, y_hi, ...), returns lo = (x_lo, y_lo, ...), hi = (x_hi, y_hi, ...).\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.translate-Union{Tuple{N}, Tuple{C}, Tuple{AbstractArray, Tuple{Vararg{Int64, C}}, Tuple{Vararg{Int64, N}}, CartesianIndex{N}}} where {C, N}","page":"Reference","title":"ConvolutionalRBMs.translate","text":"translate(v, channel_size, input_size, Δ; mode = :pad, fillvalue = 0)\n\nTranslates an image along input dimensions by Δ.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConvolutionalRBMs.vsizes-Tuple{ConvolutionalRBMs.ConvRBM, AbstractArray}","page":"Reference","title":"ConvolutionalRBMs.vsizes","text":"vsizes(convrbm, v) -> (channel_size, input_size, batch_size)\n\nReturns a (named) tuple decomposition of the size of v, such that:\n\nsize(v) == (channel_size..., input_size..., batch_size...)\n\nThrows an error if v is not consistent with this size.\n\n\n\n\n\n","category":"method"},{"location":"#ConvolutionalRBMs.jl-Documentation","page":"Home","title":"ConvolutionalRBMs.jl Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A Julia package to train and simulate convolutional Restricted Boltzmann Machines. The package is not registered. Install with:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(url=\"https://github.com/cossio/ConvolutionalRBMs.jl\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package doesn't export any symbols.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Most of the functions have a helpful docstring. See Reference section.","category":"page"},{"location":"","page":"Home","title":"Home","text":"See also the Examples listed on the menu on the left side bar.","category":"page"},{"location":"#Related","page":"Home","title":"Related","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"See also https://github.com/cossio/RestrictedBoltzmannMachines.jl.","category":"page"},{"location":"literate/MNIST_dense/","page":"MNIST dense","title":"MNIST dense","text":"EditURL = \"https://github.com/cossio/ConvolutionalRBMs.jl/blob/master/docs/src/literate/MNIST_dense.jl\"","category":"page"},{"location":"literate/MNIST_dense/#MNIST","page":"MNIST dense","title":"MNIST","text":"","category":"section"},{"location":"literate/MNIST_dense/","page":"MNIST dense","title":"MNIST dense","text":"We begin by importing the required packages. We load MNIST via the MLDatasets.jl package.","category":"page"},{"location":"literate/MNIST_dense/","page":"MNIST dense","title":"MNIST dense","text":"import Makie\nimport CairoMakie\nimport MLDatasets\nimport Flux\nimport RestrictedBoltzmannMachines as RBMs\nimport ConvolutionalRBMs as ConvRBMs\nusing Statistics: mean\nusing ValueHistories: MVHistory\nusing Random: bitrand\nusing RestrictedBoltzmannMachines: visible, hidden, weights\nnothing #hide","category":"page"},{"location":"literate/MNIST_dense/","page":"MNIST dense","title":"MNIST dense","text":"Useful function to plot MNIST digits.","category":"page"},{"location":"literate/MNIST_dense/","page":"MNIST dense","title":"MNIST dense","text":"\"\"\"\n    imggrid(A)\n\nGiven a four dimensional tensor `A` of size `(width, height, ncols, nrows)`\ncontaining `width x height` images in a grid of `nrows x ncols`, this returns\na matrix of size `(width * ncols, height * nrows)`, that can be plotted in a heatmap\nto display all images.\n\"\"\"\nfunction imggrid(A::AbstractArray{<:Any,4})\n    return reshape(permutedims(A, (1,3,2,4)), size(A,1)*size(A,3), size(A,2)*size(A,4))\nend","category":"page"},{"location":"literate/MNIST_dense/","page":"MNIST dense","title":"MNIST dense","text":"Load MNIST dataset.","category":"page"},{"location":"literate/MNIST_dense/","page":"MNIST dense","title":"MNIST dense","text":"Float = Float32\ntrain_x, train_y = MLDatasets.MNIST.traindata()\ntrain_x = Array{Float}(train_x[:, :, train_y .== 2] .≥ 0.5)\ntrain_y = train_y[train_y .== 2]\nprintln(length(train_y), \" training images\")\nnothing #hide","category":"page"},{"location":"literate/MNIST_dense/","page":"MNIST dense","title":"MNIST dense","text":"Reshape for convolutional input","category":"page"},{"location":"literate/MNIST_dense/","page":"MNIST dense","title":"MNIST dense","text":"train_x = reshape(train_x, 1, 28, 28, :) # channel dims, input dims, batch dims\nnothing #hide\n\n#= Initialize the convolutional RBM. Since the kernel size is equal to the\nimage size (28,28), this is actually equivalent to having a dense RBM. =#\n\nrbm = ConvRBMs.BinaryConvRBM(Float, 1, 200, (28,28); pad=0, pool=false)\nRBMs.initialize!(rbm, train_x)\nnothing #hide","category":"page"},{"location":"literate/MNIST_dense/","page":"MNIST dense","title":"MNIST dense","text":"Train","category":"page"},{"location":"literate/MNIST_dense/","page":"MNIST dense","title":"MNIST dense","text":"history = ConvRBMs.pcd!(rbm, train_x; epochs=100, batchsize=256)\nnothing #hide","category":"page"},{"location":"literate/MNIST_dense/","page":"MNIST dense","title":"MNIST dense","text":"Now let's generate some random RBM samples.","category":"page"},{"location":"literate/MNIST_dense/","page":"MNIST dense","title":"MNIST dense","text":"nrows, ncols = 10, 15\n@time fantasy_x = RBMs.sample_v_from_v(rbm, bitrand(1,28,28,nrows*ncols); steps=1000)\nnothing #hide","category":"page"},{"location":"literate/MNIST_dense/","page":"MNIST dense","title":"MNIST dense","text":"Plot the resulting samples.","category":"page"},{"location":"literate/MNIST_dense/","page":"MNIST dense","title":"MNIST dense","text":"fig = Makie.Figure(resolution=(40ncols, 40nrows))\nax = Makie.Axis(fig[1,1], yreversed=true)\nMakie.image!(ax, imggrid(reshape(fantasy_x, 28, 28, ncols, nrows)), colorrange=(1,0))\nMakie.hidedecorations!(ax)\nMakie.hidespines!(ax)\nfig","category":"page"},{"location":"literate/MNIST_dense/","page":"MNIST dense","title":"MNIST dense","text":"","category":"page"},{"location":"literate/MNIST_dense/","page":"MNIST dense","title":"MNIST dense","text":"This page was generated using Literate.jl.","category":"page"}]
}
